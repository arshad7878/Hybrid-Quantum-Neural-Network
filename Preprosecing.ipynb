{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2018 Xanadu Quantum Technologies Inc.\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\"For processing data from https://www.kaggle.com/mlg-ulb/creditcardfraud\"\"\"\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# creditcard.csv downloaded from https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "with open('creditcard.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "\n",
    "    data = list(csv_reader)\n",
    "\n",
    "data = data[1:]\n",
    "data_genuine = []\n",
    "data_fraudulent = []\n",
    "\n",
    "# Splitting genuine and fraudulent data\n",
    "for i in range(len(data)):\n",
    "    if int(data[i][30]) == 0:\n",
    "        data_genuine.append([float(i) for i in data[i]])\n",
    "    if int(data[i][30]) == 1:\n",
    "        data_fraudulent.append([float(i) for i in data[i]])\n",
    "\n",
    "fraudulent_data_points = len(data_fraudulent)\n",
    "\n",
    "# We want the genuine data points to be 3x the fraudulent ones\n",
    "undersampling_ratio = 3\n",
    "\n",
    "genuine_data_points = fraudulent_data_points * undersampling_ratio\n",
    "\n",
    "random.shuffle(data_genuine)\n",
    "random.shuffle(data_fraudulent)\n",
    "\n",
    "# Fraudulent and genuine transactions are split into two datasets for cross validation\n",
    "\n",
    "data_fraudulent_1 = data_fraudulent[:int(fraudulent_data_points / 2)]\n",
    "data_fraudulent_2 = data_fraudulent[int(fraudulent_data_points / 2):]\n",
    "\n",
    "data_genuine_1 = data_genuine[:int(genuine_data_points / 2)]\n",
    "data_genuine_2 = data_genuine[int(genuine_data_points / 2):genuine_data_points]\n",
    "data_genuine_remaining = data_genuine[genuine_data_points:]\n",
    "\n",
    "random.shuffle(data_fraudulent_1)\n",
    "random.shuffle(data_fraudulent_2)\n",
    "random.shuffle(data_genuine_1)\n",
    "random.shuffle(data_genuine_2)\n",
    "\n",
    "np.savetxt('creditcard_genuine_1.csv', data_genuine_1, delimiter=',')\n",
    "np.savetxt('creditcard_genuine_2.csv', data_genuine_2, delimiter=',')\n",
    "np.savetxt('creditcard_fraudulent_1.csv', data_fraudulent_1, delimiter=',')\n",
    "np.savetxt('creditcard_fraudulent_2.csv', data_fraudulent_2, delimiter=',')\n",
    "# Larger datasets are used for testing, including genuine transactions unseen in training\n",
    "np.savetxt('creditcard_combined_1_big.csv', data_fraudulent_1 + data_genuine_1 + data_genuine_remaining, delimiter=',')\n",
    "np.savetxt('creditcard_combined_2_big.csv', data_fraudulent_2 + data_genuine_2 + data_genuine_remaining, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
